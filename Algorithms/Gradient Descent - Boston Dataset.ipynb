{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "                   \n",
    "def gd(x,y,alpha,num_iterations):\n",
    "    converged = False\n",
    "    iter = 0\n",
    "    N = x.shape[0] \n",
    "\n",
    "    m = np.zeros(x.shape[1]+1)\n",
    "    #c = np.ones(x.shape[1])\n",
    "\n",
    "\n",
    "\n",
    "    while not converged:\n",
    "     \n",
    "        grad0 = (1/N) * sum([(c + m*x[i] - y[i]) for i in range(N)]) \n",
    "        grad1 = (1/N) * sum([(c + m*x[i] - y[i])*x[i] for i in range(N)])\n",
    "\n",
    "  \n",
    "        temp0 = c - alpha * grad0\n",
    "        temp1 = m - alpha * grad1\n",
    "\n",
    "      \n",
    "        new_c = temp0\n",
    "        new_m = temp1\n",
    "\n",
    "       \n",
    "        cost= sum( [ (new_c + new_m*x[i] - y[i])**2 for i in range(N) ] ) \n",
    "\n",
    "        #print(iter, 'Cost :', cost)\n",
    "        #print()\n",
    "        iter += 1  \n",
    "\n",
    "        if iter == num_iterations:\n",
    "            #print('Max interactions exceeded!')\n",
    "            converged = True\n",
    "\n",
    "    return new_c,new_m\n",
    "\n",
    "def run():\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    data=pd.read_csv(\"training_boston_x_y_train.csv\",delimiter=',')\n",
    "    data['C']=np.ones(len(data))\n",
    "    data['YY']=data[' Y']\n",
    "    del data[' Y']\n",
    "    dat=np.array(data)\n",
    "    x=dat[:,0:-1]\n",
    "    y=dat[:,-1]\n",
    "    alpha = 0.001\n",
    "    num_iterations = 1000\n",
    "    m= gd(x,y, alpha, num_iterations)\n",
    "    return m\n",
    "\n",
    "m,c=run()\n",
    "\n",
    "x_test=np.genfromtxt('test_boston_x_test.csv',delimiter=',')\n",
    "def predict(x,m,c):\n",
    "    N=len(x)\n",
    "    y=[]\n",
    "    for i in range(N):\n",
    "        z=[]\n",
    "        z.append(sum((m[j]*x[i,j]+c[j] for j in range(13))))\n",
    "        y.append(z[0])\n",
    "        z=[]\n",
    "    return y\n",
    "\n",
    "y_pred=np.array(predict(x_test,m,c))\n",
    "y_test_pred=np.around(y_pred,decimals=5)\n",
    "np.savetxt(\"G_d_n_ftrs_boston.csv\",y_test_pred)\n",
    "#y_test_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 16.11767,   7.10883,  15.95818,   7.00857,  -9.24568,  15.24419,\n",
       "        11.33802,   6.24314,  10.41348,  13.0854 ,   5.75897,  12.31064,\n",
       "         9.37787,  19.77256,  16.1356 ,  13.19917,  13.02538,  13.81482,\n",
       "        15.58339,   7.77569,   5.22366,  11.1435 ,  21.79801,  24.49211,\n",
       "        -5.2317 ,   7.66005,  19.22504,   9.04596,  15.63631,   5.83241,\n",
       "        12.40359,   8.72407,  12.97199,  -6.47983,  12.32917,  15.47216,\n",
       "         5.71558,  14.82311, -11.0043 , -13.76452,  17.1662 ,  21.79511,\n",
       "         2.64741,  -0.27289, -16.05875,  20.066  ,  10.46501,  25.24703,\n",
       "        -3.91521,  -4.59043,  27.93057,  -3.57974,   5.74219,   4.88815,\n",
       "        10.46454,   6.4363 ,  10.62335,   3.08043,  -3.78273,  -9.20396,\n",
       "        12.18505,  11.77024,  12.8698 ,  -4.70787,  -6.0747 ,  16.66933,\n",
       "        -4.10144,  11.318  ,   2.72867,  14.73938,   6.38508,  -0.11717,\n",
       "       -14.05563,  26.14816,  13.61634,  16.71397,  15.1768 ,  -5.83006,\n",
       "        24.7952 ,  -1.71898,   6.83513,  12.30378,   2.85826,  -3.26214,\n",
       "        18.55041,  17.05144, -12.96633,   3.77993,  -2.5631 ,  11.21838,\n",
       "         5.38822,   5.25048,  -7.39363,   8.13732,   6.24938,  28.20241,\n",
       "         2.22212,  22.96486,  18.29044,  11.43252,  11.47572,  13.51346,\n",
       "        15.48267,  -5.17223,  12.46274,  12.85786,  27.24825,  14.62851,\n",
       "        -6.25507,  20.77926, -17.82555,   1.47168,  -6.68158,  20.03383,\n",
       "         4.26701,   8.6662 ,  11.84476,  13.3797 ,   0.4758 ,   3.11591,\n",
       "        20.12693,   9.59437,  12.15821,  17.76942,   5.2805 ,  -3.28453])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def gd(x,y,alpha,num_iterations):\n",
    "    converged = False\n",
    "    iter = 0\n",
    "    N = x.shape[0] \n",
    "    #print(x.shape[1])\n",
    "    m = np.zeros(x.shape[1])\n",
    "    #c = np.ones(x.shape[1])\n",
    "\n",
    "\n",
    "\n",
    "    while not converged:\n",
    "     \n",
    "        #grad0 = (1/N) * sum([(c + m*x[i] - y[i]) for i in range(N)]) \n",
    "        grad1 = (1/N) * sum([( m*x[i] - y[i])*x[i] for i in range(N)])\n",
    "\n",
    "  \n",
    "        #temp0 = c - alpha * grad0\n",
    "        temp1 = m - alpha * grad1\n",
    "\n",
    "      \n",
    "        #new_c = temp0\n",
    "        new_m = temp1\n",
    "\n",
    "       \n",
    "        cost= sum( [ (new_m*x[i] - y[i])**2 for i in range(N) ] ) \n",
    "\n",
    "        #print(iter, 'Cost :', cost)\n",
    "        #print()\n",
    "        iter += 1  \n",
    "\n",
    "        if iter == num_iterations:\n",
    "            #print('Max interactions exceeded!')\n",
    "            converged = True\n",
    "\n",
    "    return new_m\n",
    "\n",
    "def run():\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    data=pd.read_csv(\"training_boston_x_y_train.csv\",delimiter=',')\n",
    "    data['C']=np.ones(len(data))\n",
    "    data['YY']=data[' Y']\n",
    "    del data[' Y']\n",
    "    dat=np.array(data)\n",
    "    #print(dat.shape)\n",
    "    x=dat[:,0:-1]\n",
    "    y=dat[:,-1]\n",
    "    alpha = 0.33\n",
    "    num_iterations = 500\n",
    "    m= gd(x,y, alpha, num_iterations)\n",
    "    return m\n",
    "\n",
    "m=run()\n",
    "\n",
    "x_tes=pd.read_csv('test_boston_x_test.csv',delimiter=',')\n",
    "xtn=np.ones(len(x_tes))\n",
    "x_tes['last']=xtn\n",
    "x_test=np.array(x_tes)\n",
    "\n",
    "def predict(x,m):\n",
    "    N=len(x)\n",
    "    y=[]\n",
    "    #print(len(m))\n",
    "    for i in range(N):\n",
    "        z=[]\n",
    "       \n",
    "        z.append(sum((m[j]*x[i,j] for j in range(len(m)))))\n",
    "        y.append(z[0])\n",
    "        z=[]\n",
    "    return y\n",
    "\n",
    "y_pred=np.array(predict(x_test,m))\n",
    "y_test_pred=np.around(y_pred,decimals=5)\n",
    "np.savetxt(\"trygradientn.csv\",y_test_pred)\n",
    "y_test_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2.91816626</th>\n",
       "      <th>-0.48772236</th>\n",
       "      <th>1.01599907</th>\n",
       "      <th>-0.27259857</th>\n",
       "      <th>0.36544404</th>\n",
       "      <th>-1.60934343</th>\n",
       "      <th>1.11749449</th>\n",
       "      <th>-1.04849446</th>\n",
       "      <th>1.66124525</th>\n",
       "      <th>1.53092646</th>\n",
       "      <th>0.80657583</th>\n",
       "      <th>-1.59755122</th>\n",
       "      <th>1.04106182</th>\n",
       "      <th>last</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>126.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.082200</td>\n",
       "      <td>-0.003515</td>\n",
       "      <td>-0.116860</td>\n",
       "      <td>-0.084932</td>\n",
       "      <td>-0.089453</td>\n",
       "      <td>-0.084088</td>\n",
       "      <td>-0.124360</td>\n",
       "      <td>0.012197</td>\n",
       "      <td>-0.143450</td>\n",
       "      <td>-0.143857</td>\n",
       "      <td>-0.064207</td>\n",
       "      <td>0.060158</td>\n",
       "      <td>-0.063663</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.725217</td>\n",
       "      <td>1.008537</td>\n",
       "      <td>0.944068</td>\n",
       "      <td>0.842620</td>\n",
       "      <td>1.007191</td>\n",
       "      <td>0.992926</td>\n",
       "      <td>1.040549</td>\n",
       "      <td>0.918999</td>\n",
       "      <td>0.936121</td>\n",
       "      <td>0.925509</td>\n",
       "      <td>1.005848</td>\n",
       "      <td>0.950202</td>\n",
       "      <td>0.957340</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.417173</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.557842</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-1.431329</td>\n",
       "      <td>-3.058221</td>\n",
       "      <td>-2.225199</td>\n",
       "      <td>-1.263551</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-1.308051</td>\n",
       "      <td>-2.707379</td>\n",
       "      <td>-3.907193</td>\n",
       "      <td>-1.496084</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.410876</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.898332</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.947582</td>\n",
       "      <td>-0.566137</td>\n",
       "      <td>-1.249062</td>\n",
       "      <td>-0.756523</td>\n",
       "      <td>-0.637962</td>\n",
       "      <td>-0.785394</td>\n",
       "      <td>-0.765457</td>\n",
       "      <td>0.263128</td>\n",
       "      <td>-0.680272</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.398921</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.406617</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.299707</td>\n",
       "      <td>-0.122712</td>\n",
       "      <td>0.073792</td>\n",
       "      <td>-0.189764</td>\n",
       "      <td>-0.523001</td>\n",
       "      <td>-0.601276</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.396098</td>\n",
       "      <td>-0.287085</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-0.246297</td>\n",
       "      <td>-0.085351</td>\n",
       "      <td>1.015999</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>0.434551</td>\n",
       "      <td>0.284384</td>\n",
       "      <td>0.889018</td>\n",
       "      <td>0.616545</td>\n",
       "      <td>-0.408041</td>\n",
       "      <td>0.004531</td>\n",
       "      <td>0.806576</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>0.352809</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.966816</td>\n",
       "      <td>3.589637</td>\n",
       "      <td>2.117615</td>\n",
       "      <td>3.668398</td>\n",
       "      <td>2.732346</td>\n",
       "      <td>3.476688</td>\n",
       "      <td>1.117494</td>\n",
       "      <td>3.287300</td>\n",
       "      <td>1.661245</td>\n",
       "      <td>1.530926</td>\n",
       "      <td>1.268938</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>3.548771</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       2.91816626  -0.48772236  1.01599907  -0.27259857  0.36544404  \\\n",
       "count  126.000000   126.000000  126.000000   126.000000  126.000000   \n",
       "mean    -0.082200    -0.003515   -0.116860    -0.084932   -0.089453   \n",
       "std      0.725217     1.008537    0.944068     0.842620    1.007191   \n",
       "min     -0.417173    -0.487722   -1.557842    -0.272599   -1.431329   \n",
       "25%     -0.410876    -0.487722   -0.898332    -0.272599   -0.947582   \n",
       "50%     -0.398921    -0.487722   -0.406617    -0.272599   -0.299707   \n",
       "75%     -0.246297    -0.085351    1.015999    -0.272599    0.434551   \n",
       "max      3.966816     3.589637    2.117615     3.668398    2.732346   \n",
       "\n",
       "       -1.60934343  1.11749449  -1.04849446  1.66124525  1.53092646  \\\n",
       "count   126.000000  126.000000   126.000000  126.000000  126.000000   \n",
       "mean     -0.084088   -0.124360     0.012197   -0.143450   -0.143857   \n",
       "std       0.992926    1.040549     0.918999    0.936121    0.925509   \n",
       "min      -3.058221   -2.225199    -1.263551   -0.982843   -1.308051   \n",
       "25%      -0.566137   -1.249062    -0.756523   -0.637962   -0.785394   \n",
       "50%      -0.122712    0.073792    -0.189764   -0.523001   -0.601276   \n",
       "75%       0.284384    0.889018     0.616545   -0.408041    0.004531   \n",
       "max       3.476688    1.117494     3.287300    1.661245    1.530926   \n",
       "\n",
       "       0.80657583  -1.59755122  1.04106182   last  \n",
       "count  126.000000   126.000000  126.000000  126.0  \n",
       "mean    -0.064207     0.060158   -0.063663    1.0  \n",
       "std      1.005848     0.950202    0.957340    0.0  \n",
       "min     -2.707379    -3.907193   -1.496084    1.0  \n",
       "25%     -0.765457     0.263128   -0.680272    1.0  \n",
       "50%      0.113032     0.396098   -0.287085    1.0  \n",
       "75%      0.806576     0.441052    0.352809    1.0  \n",
       "max      1.268938     0.441052    3.548771    1.0  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test=np.genfromtxt('test_boston_x_test.csv',delimiter=',')\n",
    "xtn=np.ones(len(x_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
